{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4 Lab: MNIST - Handwritten digits database\n",
    "\n",
    "## Overview\n",
    "\n",
    "The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems. MNIST is like the \"Hello World\" of machine learning with which you can try out a few machine learning algorithms.\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For easy to understand how this data set was built, I get an example image, which contains number 7, from mist.\n",
    "1. Resize it from 28x28 to 10X10 and make diagram. Each pixel in image contains value from 0 to 255. The greater the number, the whiter the color. That is the way how people encode the image. [Link](https://www.scan2cad.com/tips/bitmap-vs-vector/) for further information.\n",
    "2. Because each observation should be one line in dataset so we reshape 2-D array to 1-D array. Using 1-D array as feature vector and label it. In our case, it's 7.\n",
    "3. Do it again with the other images from mist. We will have a table with feature vector and label. Take a close look at first and third observation. The pattern of them are much similar than second observation. Base on this thing, we hope that can build a model that classify a number using feature vector.\n",
    "\n",
    "Let's do it.\n",
    "![Imgur](https://i.imgur.com/wtFCKS3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "1. Read dataset\n",
    "    - Dataset is too large (42000 observation) for some computer. To make it easy to handle, we get 5000 sample from origin dataset\n",
    "    - Split data set into train and test set\n",
    "2. Visualization\n",
    "    - Visualization helps you understand more about data set. Grab an observation and visualize it.\n",
    "3. Modeling\n",
    "    - We try with 2 tree base model:\n",
    "        - Decision Tree\n",
    "        - Random Forest\n",
    "4. Evaluate model\n",
    "    - Calculate accuracy, precision, recall, f1 score with each model.\n",
    "    - Random Forest vs Decision Tree, which one is better.\n",
    "5. Fine Tune\n",
    "    - Random Forest has many hyper parameters that we have to choose, so which combination is bet fit with our data set? Using gridsearchCV to find it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "# Your code here\n",
    "data = pd.read_csv(\"path_to_csv_file\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For easy to handle, we use a small pice of dataset\n",
    "# Ramdomly choose 5000 rows for now\n",
    "# hint: dataframe.sample(5000)\n",
    "# Your code here\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at first 5 rows ()\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning lighter. This pixel-value is an integer between 0 and 255, inclusive.\n",
    "\n",
    "Visually, if we omit the \"pixel\" prefix, the pixels make up the image like this:\n",
    "```\n",
    "000 001 002 003 ... 026 027\n",
    "028 029 030 031 ... 054 055\n",
    "056 057 058 059 ... 082 083\n",
    " |   |   |   |  ...  |   |\n",
    "728 729 730 731 ... 754 755\n",
    "756 757 758 759 ... 782 783 \n",
    "```\n",
    "![image](https://i.imgur.com/lFxwGOf.png=500x500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's list all unique values are there in 'label'\n",
    "# We expect to see a list from 0 to 9\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's defines X and y for train_test_split \n",
    "# y should be values of the column 'label' and X should contain the rest (784 pixel columns)\n",
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "# Let's split X and y to X_train, y_train, X_test, y_test with 25% test size and random state 101\n",
    "# Your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's convert some example of our data back to image\n",
    "# Let's start with choosing a random integer number called 'index', your choice but it shouldn't be greater than 5000\n",
    "# Let's print out y_train[index] which is the number of the image\n",
    "# Using plt.imshow(img, cmap='gray') we can plot the image. But img here should be 28x28 in height and width.\n",
    "# So before plotting we need to transform the vector X_train[index] into 28x28 Matrix with the function reshape()\n",
    "# Here is an example:\n",
    "# a = np.arange(6).reshape((3, 2))\n",
    "# >>> a\n",
    "# array([[0, 1],\n",
    "#        [2, 3],\n",
    "#        [4, 5]])\n",
    "# Now we try to look at the number with index is 36, you can try with different index for exp: 30, 49\n",
    "index = 36\n",
    "print(\"Label: \" + str(y_train[index]))\n",
    "plt.imshow(X_train[index].reshape((28,28)),cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest & Decision Tree\n",
    "# Let's define two classifier called rfc and dtc represent RandomForestClassifier and DecisionTreeClassifier\n",
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fit training data to Random Forest Classifier\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fit training data to Decision Tree Classifier\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's apply our models to testing set and take a look at accuracy score first\n",
    "# Random Forest model\n",
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree model\n",
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember seaborn with its amazing heatmap()? \n",
    "# Actually we can use heatmap() to visualize the confustion matrix\n",
    "# Just for example about the style of heatmap: cmap=\"YlGnBu\", annot=True, fmt=\"d\"\n",
    "\n",
    "# Let's plot the heatmap for confusion matrix of Random Forest model\n",
    "# Your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And heatmap for confusion matrix of Decision Tree model\n",
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fine Tune\n",
    "[Further reading](https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base on the accuracy score we decide to take Random Forest as our Classifier and we're going to improve it\n",
    "# Now let's take a look at the parameter 'n_estimators' which is the number of trees in the forest\n",
    "# Do you think the more tree we have the better our model will be?\n",
    "\n",
    "# Let's plot the correlation between n_estimators and accuracy\n",
    "# Define an array of number called 'n', n should be set of 'n_estimators' that we're going to test\n",
    "n = [1 ,5 ,10, 20, 50, 100, 200, 500]\n",
    "# Define a 'result' array to save the accuracy score of each trial\n",
    "result = []\n",
    "# Using a for-loop which goes through n\n",
    "# Inside the loop we will define a new RandomForestClassifier model with appropriate 'n_estimators'\n",
    "# Then apply that model on X_test and calculate the accuracy score then save it into 'result'\n",
    "# Your code here\n",
    "for i in n:\n",
    "    clf = RandomForestClassifier(# Your code here)\n",
    "    clf.fit(# Your code here)\n",
    "    predictions = clf.predict(# Your code here)\n",
    "    result.append(accuracy_score(# Your code here))    \n",
    "# Last step let's plot n and result on a grid using plt.scatter()\n",
    "plt.scatter(# Your code here)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
